"""
ç‰¹å¾å·¥ç¨‹å¢å¼ºè„šæœ¬
================

åœ¨ final_training_data.csv åŸºç¡€ä¸Šæ·»åŠ ä»¥ä¸‹ç‰¹å¾ï¼š

1. ç‰©ç†ç‰¹å¾ï¼š
   - fcd_flow_per_length: å•ä½é•¿åº¦æµ®åŠ¨è½¦ç´¯è®¡é‡
   - theoretical_flow: ç†è®ºæµé‡ (fcd_flow * fcd_speed / length)
   - density_proxy: å¯†åº¦ä»£ç† (fcd_flow / (length * fcd_speed))

2. æ—¶é—´ç¼–ç ï¼š
   - hour: å°æ—¶ (0-23)
   - hour_sin, hour_cos: å°æ—¶å‘¨æœŸç¼–ç 
   - weekday: æ˜ŸæœŸå‡  (0=å‘¨ä¸€, 6=å‘¨æ—¥)
   - weekday_sin, weekday_cos: æ˜ŸæœŸå‘¨æœŸç¼–ç 
   - is_weekend: æ˜¯å¦å‘¨æœ«
   - time_period: æ—¶æ®µåˆ†ç±» (å¤œé—´/æ—©é«˜å³°/å¹³å³°/æ™šé«˜å³°ç­‰)

3. é“è·¯ç±»å‹ç¼–ç ï¼š
   - kind_x: åŸå§‹é“è·¯ç±»å‹ä»£ç 
   - road_type_name: é“è·¯ç±»å‹åç§°
   - kind_01 ~ kind_06: é“è·¯ç±»å‹ One-Hot ç¼–ç 

4. è½¦é“æ•°ç¼–ç ï¼š
   - width: åŸå§‹è½¦é“åˆ†æ¡£å€¼
   - lane_category: è½¦é“æ•°ç±»åˆ« (1è½¦é“/2-3è½¦é“/4è½¦é“åŠä»¥ä¸Š)
   - lane_1, lane_2_3, lane_4_plus: è½¦é“æ•° One-Hot ç¼–ç 

5. è·¯å†µç‰¹å¾ï¼š
   - fcd_status: åŸå§‹è·¯å†µå€¼ (èšåˆåçš„å¹³å‡å€¼)
   - status_level: è·¯å†µç­‰çº§åˆ†ç±»
   - is_congested: æ˜¯å¦æ‹¥å µ (status >= 2.5)

ç”¨æ³•:
    python 7_feature_engineering.py
    python 7_feature_engineering.py --input final_training_data.csv
"""

import pandas as pd
import numpy as np
import argparse
import sys
from pathlib import Path

# === è·¯å¾„è®¾ç½® ===
current_file = Path(__file__).resolve()
src_dir = current_file.parent.parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from utils.path_manager import pm


# === é…ç½® ===
CONFIG = {
    'input_file': 'final_training_data.csv',
    'output_file': 'training_data_with_features_new.csv',
    'output_report': 'report_feature_engineering.txt',
    
    # é“è·¯ç±»å‹æ˜ å°„
    'road_kind_mapping': {
        '00': 'é«˜é€Ÿå…¬è·¯',
        '01': 'åŸå¸‚é«˜é€Ÿ',
        '02': 'å›½é“',
        '03': 'çœé“',
        '04': 'å¿é“',
        '06': 'å¸‚é•‡æ‘é“'
    },
    
    # è½¦é“æ•°æ˜ å°„ (widthå€¼ -> è½¦é“ç±»åˆ«)
    'lane_mapping': {
        30: '1è½¦é“',
        55: '2-3è½¦é“',
        130: '4è½¦é“åŠä»¥ä¸Š'
    },
    
    # è·¯å†µç­‰çº§æ˜ å°„
    'status_mapping': {
        0: 'æ— è·¯å†µ',
        1: 'ç•…é€š',
        2: 'ç¼“æ…¢(è½»åº¦)',
        3: 'ç¼“æ…¢(é‡åº¦)',
        4: 'æ‹¥å µ',
        5: 'ä¸¥é‡æ‹¥å µ'
    },
    
    # æ—¶æ®µåˆ’åˆ†
    'time_periods': {
        (0, 6): 'å¤œé—´',
        (7, 9): 'æ—©é«˜å³°',
        (10, 11): 'ä¸Šåˆå¹³å³°',
        (12, 13): 'åˆé—´',
        (14, 16): 'ä¸‹åˆå¹³å³°',
        (17, 19): 'æ™šé«˜å³°',
        (20, 23): 'æ™šé—´',
    }
}


def add_time_features(df):
    """æ·»åŠ æ—¶é—´ç›¸å…³ç‰¹å¾"""
    print("\n[1/5] æ·»åŠ æ—¶é—´ç‰¹å¾...")
    
    # è§£ææ—¶é—´
    df['start_time'] = pd.to_datetime(df['å¼€å§‹æ—¶é—´'])
    
    # åŸºç¡€æ—¶é—´ç‰¹å¾
    df['hour'] = df['start_time'].dt.hour
    df['weekday'] = df['start_time'].dt.weekday  # 0=å‘¨ä¸€, 6=å‘¨æ—¥
    df['date'] = df['start_time'].dt.date
    
    # å‘¨æœŸç¼–ç  (ç”¨äºæ•æ‰å‘¨æœŸæ€§)
    # å°æ—¶: 24å°æ—¶å‘¨æœŸ
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    
    # æ˜ŸæœŸ: 7å¤©å‘¨æœŸ
    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)
    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)
    
    # æ˜¯å¦å‘¨æœ«
    df['is_weekend'] = (df['weekday'] >= 5).astype(int)
    
    # æ—¶æ®µåˆ†ç±»
    def get_time_period(hour):
        for (start, end), period_name in CONFIG['time_periods'].items():
            if start <= hour <= end:
                return period_name
        return 'å…¶ä»–'
    
    df['time_period'] = df['hour'].apply(get_time_period)
    
    # æ—¶æ®µ One-Hot ç¼–ç 
    time_period_dummies = pd.get_dummies(df['time_period'], prefix='period')
    df = pd.concat([df, time_period_dummies], axis=1)
    
    print(f"  âœ“ hour, weekday, å‘¨æœŸç¼–ç  (sin/cos)")
    print(f"  âœ“ is_weekend")
    print(f"  âœ“ time_period + One-Hot ({df['time_period'].nunique()} ç±»)")
    
    return df


def add_road_type_features(df):
    """æ·»åŠ é“è·¯ç±»å‹ç‰¹å¾"""
    print("\n[2/5] æ·»åŠ é“è·¯ç±»å‹ç‰¹å¾...")
    
    # ç¡®ä¿ kind_x æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    df['kind_x'] = df['kind_x'].astype(str).str.zfill(2)
    
    # é“è·¯ç±»å‹åç§°
    df['road_type_name'] = df['kind_x'].map(CONFIG['road_kind_mapping']).fillna('æœªçŸ¥')
    
    # One-Hot ç¼–ç 
    kind_dummies = pd.get_dummies(df['kind_x'], prefix='kind')
    df = pd.concat([df, kind_dummies], axis=1)
    
    # ç»Ÿè®¡
    kind_dist = df['kind_x'].value_counts()
    print(f"  âœ“ road_type_name")
    print(f"  âœ“ kind One-Hot ç¼–ç ")
    print(f"  é“è·¯ç±»å‹åˆ†å¸ƒ:")
    for kind_code, count in kind_dist.items():
        kind_name = CONFIG['road_kind_mapping'].get(kind_code, 'æœªçŸ¥')
        print(f"    - {kind_code} ({kind_name}): {count} æ¡ ({count/len(df)*100:.1f}%)")
    
    return df


def add_lane_features(df):
    """æ·»åŠ è½¦é“æ•°ç‰¹å¾"""
    print("\n[3/5] æ·»åŠ è½¦é“æ•°ç‰¹å¾...")
    
    # è½¦é“ç±»åˆ«
    df['lane_category'] = df['width'].map(CONFIG['lane_mapping']).fillna('æœªçŸ¥')
    
    # One-Hot ç¼–ç 
    df['lane_1'] = (df['width'] == 30).astype(int)
    df['lane_2_3'] = (df['width'] == 55).astype(int)
    df['lane_4_plus'] = (df['width'] == 130).astype(int)
    
    # ç»Ÿè®¡
    lane_dist = df['lane_category'].value_counts()
    print(f"  âœ“ lane_category")
    print(f"  âœ“ lane One-Hot ç¼–ç  (lane_1, lane_2_3, lane_4_plus)")
    print(f"  è½¦é“æ•°åˆ†å¸ƒ:")
    for lane_cat, count in lane_dist.items():
        print(f"    - {lane_cat}: {count} æ¡ ({count/len(df)*100:.1f}%)")
    
    return df


def add_status_features(df):
    """æ·»åŠ è·¯å†µç‰¹å¾"""
    print("\n[4/5] æ·»åŠ è·¯å†µç‰¹å¾...")
    
    # è·¯å†µç­‰çº§åˆ†ç±» (åŸºäºèšåˆåçš„å¹³å‡å€¼)
    def get_status_level(status):
        if pd.isna(status):
            return 'æ— æ•°æ®'
        elif status < 0.5:
            return 'æ— è·¯å†µ'
        elif status < 1.5:
            return 'ç•…é€š'
        elif status < 2.5:
            return 'ç¼“æ…¢(è½»åº¦)'
        elif status < 3.5:
            return 'ç¼“æ…¢(é‡åº¦)'
        elif status < 4.5:
            return 'æ‹¥å µ'
        else:
            return 'ä¸¥é‡æ‹¥å µ'
    
    df['status_level'] = df['fcd_status'].apply(get_status_level)
    
    # æ˜¯å¦æ‹¥å µ (status >= 2.5ï¼Œå³ç¼“æ…¢é‡åº¦åŠä»¥ä¸Š)
    df['is_congested'] = (df['fcd_status'] >= 2.5).astype(int)
    
    # è·¯å†µ One-Hot ç¼–ç 
    status_dummies = pd.get_dummies(df['status_level'], prefix='status')
    df = pd.concat([df, status_dummies], axis=1)
    
    # ç»Ÿè®¡
    status_dist = df['status_level'].value_counts()
    print(f"  âœ“ status_level")
    print(f"  âœ“ is_congested")
    print(f"  âœ“ status One-Hot ç¼–ç ")
    print(f"  è·¯å†µåˆ†å¸ƒ:")
    for status_name, count in status_dist.items():
        print(f"    - {status_name}: {count} æ¡ ({count/len(df)*100:.1f}%)")
    
    congested_ratio = df['is_congested'].mean()
    print(f"  æ‹¥å µæ¯”ä¾‹: {congested_ratio:.1%}")
    
    return df


def add_physical_features(df):
    """æ·»åŠ ç‰©ç†/ç†è®ºç‰¹å¾"""
    print("\n[5/5] æ·»åŠ ç‰©ç†ç‰¹å¾...")
    
    # ç¡®ä¿æ•°å€¼åˆ—
    df['fcd_flow'] = pd.to_numeric(df['fcd_flow'], errors='coerce').fillna(0)
    df['fcd_speed'] = pd.to_numeric(df['fcd_speed'], errors='coerce')
    df['length'] = pd.to_numeric(df['length'], errors='coerce')
    
    # 1. å•ä½é•¿åº¦æµ®åŠ¨è½¦ç´¯è®¡é‡
    # fcd_flow æ˜¯"è½¦Â·ç§’"ç´¯è®¡ï¼Œé™¤ä»¥é•¿åº¦å¾—åˆ°å•ä½é•¿åº¦çš„ç´¯è®¡
    df['fcd_flow_per_length'] = df.apply(
        lambda r: r['fcd_flow'] / r['length'] if r['length'] > 0 else 0,
        axis=1
    )
    
    # 2. ç†è®ºæµé‡ä¼°è®¡
    # åŸºäºäº¤é€šæµç†è®º: Q = N * v / L
    # å…¶ä¸­ N æ˜¯åœ¨é€”è½¦è¾†æ•°ï¼Œv æ˜¯é€Ÿåº¦ï¼ŒL æ˜¯è·¯æ®µé•¿åº¦
    # fcd_flow â‰ˆ N * T (T=3600ç§’)ï¼Œæ‰€ä»¥ N â‰ˆ fcd_flow / 3600
    # Q â‰ˆ (fcd_flow / 3600) * v / L = fcd_flow * v / (3600 * L)
    df['theoretical_flow'] = df.apply(
        lambda r: (r['fcd_flow'] * r['fcd_speed'] / (3600 * r['length'])) 
                  if (r['length'] > 0 and pd.notna(r['fcd_speed']) and r['fcd_speed'] > 0) else 0,
        axis=1
    )
    
    # 3. å¯†åº¦ä»£ç†
    # äº¤é€šå¯†åº¦ K = N / L â‰ˆ fcd_flow / (3600 * L)
    # æˆ–è€… K = Q / vï¼Œè¿™é‡Œç”¨ fcd_flow / (length * speed) ä½œä¸ºä»£ç†
    # df['density_proxy'] = df.apply(
    #     lambda r: r['fcd_flow'] / (r['length'] * r['fcd_speed'])
    #               if (r['length'] > 0 and pd.notna(r['fcd_speed']) and r['fcd_speed'] > 0) else 0,
    #     axis=1
    # )
    # ä¿®æ”¹åï¼šçœŸæ­£çš„å¯†åº¦ K (Veh/km)
    df['density_proxy'] = df.apply(
        lambda r: r['fcd_flow'] / (3600 * r['length'])
        if r['length'] > 0 else 0,
        axis=1
    )
    
    # 4. é€Ÿåº¦-æµé‡äº¤äº’ç‰¹å¾
    df['speed_flow_interaction'] = df['fcd_flow'] * df['fcd_speed']
    
    # 5. æ¯”å€¼ç‰¹å¾ (ç”¨äºåˆ†æ)
    df['ratio'] = df.apply(
        lambda r: r['flow_std'] / r['fcd_flow'] if r['fcd_flow'] > 0 else np.nan,
        axis=1
    )
    
    # ç»Ÿè®¡
    print(f"  âœ“ fcd_flow_per_length: å•ä½é•¿åº¦æµ®åŠ¨è½¦ç´¯è®¡")
    print(f"  âœ“ theoretical_flow: ç†è®ºæµé‡ (fcd_flow * speed / (3600 * length))")
    print(f"  âœ“ density_proxy: å¯†åº¦ä»£ç†")
    print(f"  âœ“ speed_flow_interaction: é€Ÿåº¦-æµé‡äº¤äº’")
    print(f"  âœ“ ratio: å¡å£/æµ®åŠ¨è½¦æ¯”å€¼ (ç”¨äºåˆ†æ)")
    
    # æ£€æŸ¥ç†è®ºæµé‡ä¸å®é™…æµé‡çš„ç›¸å…³æ€§
    valid_mask = (df['theoretical_flow'] > 0) & (df['flow_std'] > 0)
    if valid_mask.sum() > 100:
        corr = df.loc[valid_mask, 'theoretical_flow'].corr(df.loc[valid_mask, 'flow_std'])
        print(f"\n  theoretical_flow ä¸ flow_std ç›¸å…³ç³»æ•°: {corr:.4f}")
    
    return df


def generate_report(df, output_path):
    """ç”Ÿæˆç‰¹å¾å·¥ç¨‹æŠ¥å‘Š"""
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("ç‰¹å¾å·¥ç¨‹æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"æ•°æ®é‡: {len(df)} æ¡\n")
        f.write(f"å¡å£æ•°: {df['å¡å£ç¼–å·'].nunique()}\n")
        f.write(f"ç‰¹å¾æ•°: {len(df.columns)}\n\n")
        
        # ç‰¹å¾åˆ—è¡¨
        f.write("-" * 40 + "\n")
        f.write("ç‰¹å¾åˆ—è¡¨\n")
        f.write("-" * 40 + "\n")
        
        feature_groups = {
            'åŸå§‹ç‰¹å¾': ['å¡å£ç¼–å·', 'å¡å£åç§°', 'Link_ID', 'å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´', 
                       'flow_large', 'flow_small', 'flow_std', 
                       'fcd_flow', 'fcd_speed', 'fcd_status', 'fcd_record_count',
                       'kind_x', 'width', 'length', 'penetration_rate'],
            'æ—¶é—´ç‰¹å¾': ['hour', 'weekday', 'hour_sin', 'hour_cos', 
                       'weekday_sin', 'weekday_cos', 'is_weekend', 'time_period'],
            'é“è·¯ç±»å‹': ['road_type_name'] + [c for c in df.columns if c.startswith('kind_')],
            'è½¦é“æ•°': ['lane_category', 'lane_1', 'lane_2_3', 'lane_4_plus'],
            'è·¯å†µ': ['status_level', 'is_congested'] + [c for c in df.columns if c.startswith('status_')],
            'ç‰©ç†ç‰¹å¾': ['fcd_flow_per_length', 'theoretical_flow', 'density_proxy', 
                       'speed_flow_interaction', 'ratio'],
        }
        
        for group_name, features in feature_groups.items():
            existing = [f for f in features if f in df.columns]
            f.write(f"\n{group_name} ({len(existing)}):\n")
            for feat in existing:
                f.write(f"  - {feat}\n")
        
        # æ•°å€¼ç‰¹å¾ç»Ÿè®¡
        f.write("\n" + "-" * 40 + "\n")
        f.write("å…³é”®æ•°å€¼ç‰¹å¾ç»Ÿè®¡\n")
        f.write("-" * 40 + "\n\n")
        
        key_numeric = ['flow_std', 'fcd_flow', 'fcd_speed', 'fcd_status',
                       'theoretical_flow', 'density_proxy', 'ratio']
        
        for col in key_numeric:
            if col in df.columns:
                s = df[col].dropna()
                f.write(f"{col}:\n")
                f.write(f"  mean={s.mean():.4f}, median={s.median():.4f}, std={s.std():.4f}\n")
                f.write(f"  min={s.min():.4f}, max={s.max():.4f}\n\n")
        
        # ç±»åˆ«ç‰¹å¾åˆ†å¸ƒ
        f.write("-" * 40 + "\n")
        f.write("ç±»åˆ«ç‰¹å¾åˆ†å¸ƒ\n")
        f.write("-" * 40 + "\n\n")
        
        cat_features = ['time_period', 'road_type_name', 'lane_category', 'status_level']
        for col in cat_features:
            if col in df.columns:
                f.write(f"{col}:\n")
                dist = df[col].value_counts()
                for val, count in dist.items():
                    f.write(f"  {val}: {count} ({count/len(df)*100:.1f}%)\n")
                f.write("\n")
    
    print(f"\nğŸ“„ ç‰¹å¾æŠ¥å‘Š: {output_path.name}")


def run(input_file=None):
    """æ‰§è¡Œç‰¹å¾å·¥ç¨‹"""
    print("=" * 60)
    print("ç‰¹å¾å·¥ç¨‹å¢å¼º")
    print("=" * 60)
    
    # è¯»å–æ•°æ®
    if input_file is None:
        input_file = CONFIG['input_file']
    
    input_path = pm.get_processed_path(input_file)
    print(f"è¯»å–æ•°æ®: {input_path.name}")
    df = pd.read_csv(input_path, low_memory=False)
    
    print(f"åŸå§‹æ•°æ®: {len(df)} æ¡, {len(df.columns)} åˆ—")
    
    # æ·»åŠ å„ç±»ç‰¹å¾
    df = add_time_features(df)
    df = add_road_type_features(df)
    df = add_lane_features(df)
    df = add_status_features(df)
    df = add_physical_features(df)
    
    # æ¸…ç†ä¸´æ—¶åˆ—
    cols_to_drop = ['start_time', 'date']
    df.drop(columns=[c for c in cols_to_drop if c in df.columns], inplace=True)
    
    # ä¿å­˜
    output_path = pm.get_processed_path(CONFIG['output_file'])
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    # ç”ŸæˆæŠ¥å‘Š
    report_path = pm.get_processed_path(CONFIG['output_report'])
    generate_report(df, report_path)
    
    print("\n" + "=" * 60)
    print("ç‰¹å¾å·¥ç¨‹å®Œæˆ")
    print("=" * 60)
    print(f"è¾“å‡ºæ•°æ®: {len(df)} æ¡, {len(df.columns)} åˆ—")
    print(f"æ–°å¢ç‰¹å¾æ•°: {len(df.columns) - 20} (çº¦)")  # ç²—ç•¥ä¼°è®¡
    print(f"âœ… è¾“å‡ºæ–‡ä»¶: {output_path.name}")
    
    return df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç‰¹å¾å·¥ç¨‹å¢å¼º")
    parser.add_argument('--input', type=str, default=None,
                        help='è¾“å…¥æ–‡ä»¶å (é»˜è®¤: final_training_data.csv)')
    args = parser.parse_args()
    
    run(input_file=args.input)
